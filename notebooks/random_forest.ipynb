{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Tuple, List, Dict\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../scripts/')\n",
    "import utils as utl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict, Tuple\n",
    "import math\n",
    "\n",
    "class Decision_Tree_Classifier:\n",
    "    def __init__(self) -> None:\n",
    "        self.res_dict = {}\n",
    "    \n",
    "    def fit(self, X, y, X_cat_cols):\n",
    "        self.res_dict = self.des_tree_nodes(X, y, X_cat_cols)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return X.apply(lambda x: self.predict_single(x, self.res_dict), axis=1)\n",
    "\n",
    "    def predict_single(self, x, res_dict):\n",
    "        tp = res_dict['type']\n",
    "        attr = res_dict['attr']\n",
    "        if tp == 'cat':\n",
    "            if x[attr] in res_dict['res'].keys():\n",
    "                res = res_dict['res'][x[attr]]\n",
    "            else:\n",
    "                rn = random.randint(0, len(list(res_dict['res'].keys())) - 1)\n",
    "                res = res_dict['res'][list(res_dict['res'].keys())[rn]]\n",
    "        else:\n",
    "            val = res_dict['vals']\n",
    "            i = self.recover_index(x[attr],val)\n",
    "            if str(i) in res_dict['res'].keys():\n",
    "                res = res_dict['res'][str(i)]\n",
    "            else:\n",
    "                rn = random.randint(0, len(list(res_dict['res'].keys())) - 1)\n",
    "                res = res_dict['res'][list(res_dict['res'].keys())[rn]]\n",
    "            \n",
    "        \n",
    "        if isinstance(res,dict):\n",
    "            return self.predict_single(x, res)\n",
    "        else:\n",
    "            return res\n",
    "\n",
    "    def new_nodes(self, X: pd.DataFrame, y: pd.Series, attr_max_gain: str, X_cat_cols) -> Dict:\n",
    "        dct_res = {}\n",
    "        cols = list(X.columns)\n",
    "        cols.remove(attr_max_gain)\n",
    "        X_upd = X[cols]\n",
    "        Xcc = X_cat_cols.copy()\n",
    "        if attr_max_gain in X_cat_cols:\n",
    "            Xcc.remove(attr_max_gain)\n",
    "        \n",
    "        dct_res['attr'] = attr_max_gain\n",
    "        if attr_max_gain in X_cat_cols:\n",
    "            dct_res['type'] = 'cat'\n",
    "            dct_res['vals'] = np.sort(X[attr_max_gain].unique())\n",
    "            childs = {}\n",
    "\n",
    "            for u in dct_res['vals']:\n",
    "                Xn = X_upd.loc[X[attr_max_gain]==u]\n",
    "                yn = y.loc[X[attr_max_gain]==u]\n",
    "                if len(yn)>0:\n",
    "                    childs[u] = yn.iloc[0]\n",
    "                    if len(yn.unique()) > 1:\n",
    "                        childs[u] = self.des_tree_nodes(Xn, yn, Xcc)\n",
    "            dct_res['res'] = childs\n",
    "        else:\n",
    "            dct_res['type'] = 'cont'\n",
    "            splits = self.get_splits(X[attr_max_gain], y)\n",
    "            dct_res['vals'] = splits\n",
    "            childs = {}\n",
    "            for i in range(len(splits) + 1):                \n",
    "                Xn = self.iloc_ranges(X_upd, X[attr_max_gain], splits, i)\n",
    "                yn = self.iloc_ranges(y, X[attr_max_gain], splits, i)\n",
    "                if len(yn)>0:\n",
    "                    childs[str(i)] = self.des_tree_nodes(Xn, yn, Xcc)\n",
    "            dct_res['res'] = childs\n",
    "        return dct_res\n",
    "    \n",
    "    def des_tree_nodes(self, X: pd.DataFrame, y: pd.Series, X_cat_cols):\n",
    "        cols = list(X.columns)\n",
    "        attr_max_gain = self.get_max_ig(X, y, X_cat_cols)\n",
    "        cols.remove(attr_max_gain)\n",
    "        if len(cols)!=0:\n",
    "            out = self.new_nodes(X, y, attr_max_gain, X_cat_cols)\n",
    "            return out\n",
    "        y_count = {}\n",
    "        for u in y.unique():\n",
    "            y_count[u] = y.loc[y==u].count()\n",
    "        out = max(y_count, key=y_count.get)\n",
    "        return out\n",
    "    \n",
    "    def info_gain_cat(self, x:pd.Series, y:pd.Series) -> float:\n",
    "        \"\"\"Calculates the info gain of using a given categorical attribute to describe categorical data\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : pd.Series\n",
    "            Categorical values of the attribute\n",
    "        y : pd.Series\n",
    "            Categorical target\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            Information gain\n",
    "        \"\"\"\n",
    "        ES = self.entropy(y)\n",
    "        ESv = 0\n",
    "        nt = len(y)\n",
    "        if nt != 0:\n",
    "            for u in np.sort(x.unique()):\n",
    "                Sv = y.loc[x==u]\n",
    "                n = len(Sv)        \n",
    "                ESv += - (n/nt)*self.entropy(Sv)\n",
    "        return ES - ESv\n",
    "\n",
    "    def info_gain_con(self, x:pd.Series, y:pd.Series) -> float:\n",
    "        \"\"\"Calculates the info gain of using a given continuous attribute to describe categorical data\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : pd.Series\n",
    "            Categorical values of the attribute\n",
    "        y : pd.Series\n",
    "            Categorical target\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            Information gain\n",
    "        \"\"\"\n",
    "        splits = self.get_splits(x, y)\n",
    "        ES = self.entropy(y)\n",
    "        ESv = 0\n",
    "        nt = len(y)\n",
    "        if nt != 0:\n",
    "            for i in range(len(splits) + 1):\n",
    "                Sv = self.iloc_ranges(y, x, splits, i)\n",
    "                n = len(Sv)\n",
    "                ESv += - (n/nt)*self.entropy(Sv)\n",
    "        return ES - ESv\n",
    "\n",
    "    def get_max_ig(self, X: pd.DataFrame, y: pd.Series, X_cat_cols: List) -> str:\n",
    "        \"\"\"Identifies the column of X with the maximum info gain related to the target y\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pd.DataFrame\n",
    "            Input data\n",
    "        y : pd.Series\n",
    "            Target data\n",
    "        X_cat_cols : List\n",
    "            List of categorical columns of X\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            Name of the column with maximum information gain\n",
    "        \"\"\"\n",
    "        dct = {}\n",
    "        cols = list(X.columns)\n",
    "        for attr in cols:\n",
    "            if attr in X_cat_cols:\n",
    "                dct[attr] = self.info_gain_cat(X[attr], y)\n",
    "            else:\n",
    "                dct[attr] = self.info_gain_con(X[attr], y)\n",
    "        return max(dct, key=dct.get)\n",
    "    \n",
    "    def iloc_ranges(self, y: pd.Series, x: pd.Series, splits: List, i: int) -> pd.Series:\n",
    "        \"\"\"Filters the data from the series y for which the continuous data x is between the values split[i-1] and split[i]\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : pd.Series\n",
    "            Continuous data to use as base for the filtering\n",
    "        y : pd.Series or pd.DataFrame\n",
    "            Data to be filtered\n",
    "        splits : List\n",
    "            Values at which the values of x can be splitted\n",
    "        i : int\n",
    "            Index of the split to be used\n",
    "\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.Series\n",
    "            Filtered data\n",
    "        \"\"\"\n",
    "        if len(x) > 0:\n",
    "            if i > 0 and i < len(splits):\n",
    "                Sv = y.loc[(x>splits[i-1]) & (x<=splits[i])]\n",
    "            elif i == 0:\n",
    "                Sv = y.loc[x<=splits[0]]\n",
    "            else:\n",
    "                Sv = y.loc[x>splits[-1]]\n",
    "            return Sv\n",
    "        return pd.Series([])\n",
    "\n",
    "    def recover_index(self, val: float, splits: List) -> int:\n",
    "        \"\"\"Recovers the index at which val falls whitin the range of the values specified by splits\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        val : pd.Series\n",
    "            Value to evaluate\n",
    "        splits : List\n",
    "            Limits of the split ranges.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            Recovered index\n",
    "        \"\"\"\n",
    "        for i,v in enumerate(splits):\n",
    "            if i > 0:\n",
    "                if val > splits[i-1] and val <= v:\n",
    "                    return round(i)\n",
    "            else:\n",
    "                if val <= v:\n",
    "                    return round(i)\n",
    "        return round(len(splits))\n",
    "    \n",
    "    def get_splits(self, x:pd.Series, y:pd.Series) -> np.array:\n",
    "        \"\"\"Returns the splits of the categorical data x, using the median x for each category of y\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : pd.Series\n",
    "            Input data for which the splits will be calculated\n",
    "        y : pd.Series\n",
    "            Target categorical data \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        np.array\n",
    "            Limits of the splits\n",
    "        \"\"\"\n",
    "        vals = []\n",
    "        for u in y.unique():\n",
    "            x_np = x.loc[y==u].to_numpy()\n",
    "            vals.append(np.median(x_np))\n",
    "        vals_sorted = np.sort(np.unique(np.array(vals)))\n",
    "        return vals_sorted\n",
    "    \n",
    "    def entropy(self, y: pd.Series) -> float:\n",
    "        \"\"\"Calculates the entropy of y\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        y : pd.Series\n",
    "            Categorical value for which the entropy will be calculated\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            Entropy\n",
    "        \"\"\"\n",
    "        entropy = 0\n",
    "        ntt = len(y)\n",
    "        if ntt != 0:\n",
    "            for u in y.unique():\n",
    "                y_c = y.loc[y==u]\n",
    "                p = len(y_c)/ntt\n",
    "                if p != 0:\n",
    "                    entropy += -p*math.log2(p)\n",
    "        return entropy\n",
    "    \n",
    "\n",
    "class Decision_Tree_Regressor(Decision_Tree_Classifier):\n",
    "    def __init__(self, min_n_data = None) -> None:\n",
    "        super().__init__()\n",
    "        if min_n_data is None:\n",
    "            self.min_n_data = 50\n",
    "        else:\n",
    "            self.min_n_data = min_n_data\n",
    "\n",
    "    def fit(self, \n",
    "            X, y):\n",
    "        df_split = X.copy()\n",
    "        df_split['res'] = y.copy()\n",
    "        df_split['pred'] = y.copy()\n",
    "        df_split = df_split.reset_index(drop = True)\n",
    "\n",
    "        self.res_dict = self.des_tree_nodes(df_split)\n",
    "\n",
    "    def des_tree_nodes(self, df: pd.DataFrame) -> Dict:\n",
    "        dct_res = {}    \n",
    "        attr_max_gain, x_v = self.get_min_mse(df)\n",
    "\n",
    "        dct_res['type'] = 'cont'\n",
    "        dct_res['attr'] = attr_max_gain\n",
    "        splits = [x_v]\n",
    "        dct_res['vals'] = splits\n",
    "\n",
    "        childs = {}\n",
    "        df_s = df.sort_values(attr_max_gain)\n",
    "        df_low = df_s.loc[df_s[attr_max_gain] <= x_v]\n",
    "        df_high = df_s.loc[df_s[attr_max_gain] > x_v]\n",
    "\n",
    "        if len(df_low) > self.min_n_data:\n",
    "            childs['0'] = self.des_tree_nodes(df_low)\n",
    "        else:\n",
    "            childs['0'] = df_low['res'].mean()\n",
    "\n",
    "        if len(df_high) > self.min_n_data:\n",
    "            childs['1'] = self.des_tree_nodes(df_high)\n",
    "        else:\n",
    "            childs['1'] = df_high['res'].mean()\n",
    "\n",
    "        dct_res['res'] = childs\n",
    "        return dct_res\n",
    "\n",
    "    def mse(self, y: pd.Series, y_pred: pd.Series) -> float:\n",
    "        y_np = y.to_numpy()\n",
    "        yp_np = y_pred.to_numpy()\n",
    "        return np.mean((y_np - yp_np)**2)\n",
    "    \n",
    "    def get_split_pred(self, df_s: pd.DataFrame, c: str, i: int) -> Tuple[pd.Series, float]:\n",
    "        \"\"\"Splits the dataframe at the given index. Returns the predicted value as the mean of the target before and after the split.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df_s : pd.DataFrame\n",
    "            Input and target data sorted by column c\n",
    "        c : str\n",
    "            column that serves as x values\n",
    "        i : int\n",
    "            Index for splitting\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[pd.Series, float]\n",
    "            pd.Series: Predicted value with the means before and after the split\n",
    "            float: column value at which the split was performed (average of df_s[c].iloc[i] and df_s[c].iloc[i+1])\n",
    "        \"\"\"\n",
    "        x_split = np.mean([df_s[c].iloc[i-1:i+1]])\n",
    "        yA_m = df_s['res'].loc[df_s[c] <= x_split].mean()\n",
    "        yB_m = df_s['res'].loc[df_s[c] > x_split].mean()\n",
    "\n",
    "        df_s['pred'].loc[df_s[c] <= x_split] = yA_m\n",
    "        df_s['pred'].loc[df_s[c] > x_split] = yB_m    \n",
    "        return df_s['pred'], x_split\n",
    "\n",
    "    def get_min_mse_column(self, df: pd.DataFrame, c: str) -> List:\n",
    "        \"\"\"Sorts the dataframe by column c, and returns the index and value of the split necessary to minimize the mean squared error\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df : pd.DataFrame\n",
    "            Input and target data.\n",
    "        c : str\n",
    "            Column for which the splits will be performed\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        List\n",
    "            _description_\n",
    "        \"\"\"\n",
    "        mse_res = []\n",
    "        x_s = []\n",
    "        df_s = df.sort_values(c)\n",
    "        for i in range(1,len(df_s)):\n",
    "            df_s['pred'], x_split = self.get_split_pred(df_s, c, i)\n",
    "            x_s.append(x_split)\n",
    "            mse_res.append(self.mse(df_s['res'], df_s['pred']))\n",
    "\n",
    "        return [x_s[np.argmin(mse_res)],np.min(mse_res)]\n",
    "\n",
    "    def get_min_mse(self, df: pd.DataFrame) -> Tuple[str,float]:\n",
    "        \"\"\"Obtains the column and the split value of the column which allows to minimize the mse\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df : pd.DataFrame\n",
    "            Input and target dat\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[str,float]\n",
    "            str: Column that minimizes the mse\n",
    "            float: Value of df[c] at which the mse is minimized\n",
    "        \"\"\"\n",
    "        cols = [x for x in df.columns if x not in ['res','pred']]\n",
    "        x_vals = []\n",
    "\n",
    "        for c in cols:\n",
    "            x_vals.append(self.get_min_mse_column(df, c))\n",
    "\n",
    "        xv_np = np.array(x_vals)\n",
    "        min_index = np.argmin(xv_np[:,1])\n",
    "        attr = cols[min_index]\n",
    "        x_v = x_vals[min_index][0]\n",
    "\n",
    "        return attr, x_v       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Random_Forest:\n",
    "    def __init__(self, n_trees = 100) -> None:\n",
    "        self.random_forest = []\n",
    "        self.n_trees = n_trees\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y: pd.Series, X_cat_cols: List) -> None:\n",
    "        \"\"\"Fits a random forest model.  The ensemble of models is saved \n",
    "        as the list of trees (dicts) self.random_forest\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pd.DataFrame\n",
    "            Input data\n",
    "        y : pd.Series\n",
    "            Target data\n",
    "        X_cat_cols : List\n",
    "            Categorical columns\n",
    "        \"\"\"\n",
    "        # Bootstrap resample and fitting\n",
    "        n_samples = len(X)\n",
    "        self.random_forest = []\n",
    "\n",
    "        df = X.copy()\n",
    "        df['res'] = y.copy()\n",
    "\n",
    "        for i in range(self.n_trees):\n",
    "            X_bs = df.sample(n_samples,replace=True).reset_index()\n",
    "            dtc = Decision_Tree_Classifier()\n",
    "            dtc.fit(X_bs[X.columns], X_bs['res'], X_cat_cols)\n",
    "            self.random_forest.append(dtc)\n",
    "\n",
    "    # Single prediction\n",
    "    def single_predict(self, X: pd.Series) -> int:\n",
    "        \"\"\"Returns the predicted value of a single entry of input data\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pd.Series\n",
    "            Input data\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            Predicted category\n",
    "        \"\"\"\n",
    "        cv = X.to_frame().transpose()\n",
    "        y_vals = []\n",
    "        for i, dt in enumerate(self.random_forest):\n",
    "            y_vals.append(dt.predict(cv).iloc[0])\n",
    "        return max(set(y_vals), key = y_vals.count)\n",
    "    \n",
    "    def predict(self, X: pd.DataFrame) -> pd.Series:\n",
    "        \"\"\"Predicts the categories related to the input data X\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : pd.DataFrame\n",
    "            Input data\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.Series\n",
    "            Predicted categories\n",
    "        \"\"\"\n",
    "        return X.reset_index()[X.columns].apply(lambda x: self.single_predict(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/1.raw/customerClassification.csv')#, parse_dates=['DateTime'],index_col=['DateTime'])\n",
    "df.columns\n",
    "X_cols = ['Gender', 'Ever_Married', 'Age', 'Graduated', 'Profession',\n",
    "       'Work_Experience', 'Spending_Score', 'Family_Size',\n",
    "       'Segmentation']\n",
    "X_cat_cols = ['Gender', 'Ever_Married', 'Graduated', 'Profession',\n",
    "       'Spending_Score', 'Segmentation']\n",
    "y_col = 'Var_1'\n",
    "\n",
    "X = df[X_cols]\n",
    "X = X.fillna(0)\n",
    "\n",
    "for cat in X_cat_cols:\n",
    "    X[cat] = X[cat].astype('category').cat.codes\n",
    "# for c in X.columns:\n",
    "#     X[c] = utl.min_max_scaling(X[c])[0]\n",
    "\n",
    "y = df[y_col].fillna(0).astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = Random_Forest(n_trees=10)\n",
    "rf.fit(X, y, X_cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_res = rf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7413237481408032,\n",
       " 0.40404040404040403,\n",
       " 0.7612456747404844,\n",
       " 0.5278944211157768)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(formatter={'float_kind':'{:4.0f}'.format})\n",
    "cm = utl.confusion_matrix(y, y_res)\n",
    "acc = utl.accuracy_classification(cm)\n",
    "pres = utl.presicion_classification(cm, i=4)\n",
    "rec = utl.recall_classification(cm, i=4)\n",
    "f1 = utl.fbeta_classification(cm, i=4)\n",
    "\n",
    "acc, pres, rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  17,    0,    0,    2,    2,    0,   55,    0],\n",
       "       [   0,   39,    1,    1,    0,    2,   90,    0],\n",
       "       [   0,    2,   78,    3,   12,    1,  325,    1],\n",
       "       [   1,    1,    5,  215,   29,    3,  568,    0],\n",
       "       [   0,    0,    6,   18,  440,    4,  621,    0],\n",
       "       [   0,    0,    0,    0,    5,   30,   50,    0],\n",
       "       [   1,    2,    8,   19,   81,    3, 5121,    3],\n",
       "       [   0,    1,    0,    1,    9,    0,  151,   41]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlmodels",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2fd147ba20c8daf6cb1dcf6daee5f39423a22a50096e43b78394de578cc442cf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
