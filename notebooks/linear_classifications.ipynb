{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../scripts/')\n",
    "import utils as utl\n",
    "from logistic_regression import LogisticRegression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def log_reg_predict(w, X):\n",
    "#     return (w*X).sum(axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def confusion_matrix(y: pd.Series, y_p: pd.Series) -> np.array:\n",
    "#     \"\"\"Calculates the confusion matrix of a classification model\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     y : pd.Series\n",
    "#         True values\n",
    "#     y_p : pd.Series\n",
    "#         Predicted values\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     np.array\n",
    "#         Confusion Matrix\n",
    "#     \"\"\"\n",
    "#     cats = y.unique()\n",
    "#     n= len(cats)\n",
    "#     conf_matr = np.zeros((n,n))\n",
    "\n",
    "#     for i in range(len(y)):\n",
    "#         k = np.where(cats == y.iloc[i])[0][0]\n",
    "#         l = np.where(cats == y_p.iloc[i])[0][0]\n",
    "#         conf_matr[k][l] = conf_matr[k][l] + 1\n",
    "#     return conf_matr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def accuracy_classification(cm: np.array) -> float:\n",
    "#     \"\"\"Correct predictions vs total number of data points\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     cm : np.array\n",
    "#         Confusion Matrix\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     float\n",
    "#         Accuracy\n",
    "#     \"\"\"\n",
    "#     return cm.trace()/cm.sum()\n",
    "\n",
    "# def presicion_classification(cm: np.array, i: int = 0) -> float:    \n",
    "#     \"\"\"True Positives of a given category vs total number of data points\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     cm : np.array\n",
    "#         Multiclass confusion matrix\n",
    "#     i : int, optional\n",
    "#         Index of category of interests, by default 0\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     float\n",
    "#         _description_\n",
    "#     \"\"\"\n",
    "#     return cm[i][i]/cm[i].sum()\n",
    "\n",
    "# def recall_classification(cm: np.array, i: int = 0) -> float:    \n",
    "#     \"\"\"True Positives of a given category vs total number of data points\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     cm : np.array\n",
    "#         Multiclass confusion matrix\n",
    "#     i : int, optional\n",
    "#         Index of category of interests, by default 0\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     float\n",
    "#         _description_\n",
    "#     \"\"\"\n",
    "#     return cm[i][i]/cm[:,i].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fbeta_classification(cm: np.array, i: int = 0, beta: float = 1.0) -> float:\n",
    "#     p = presicion_classification(cm, i=i)\n",
    "#     r = recall_classification(cm, i=i)\n",
    "#     fb = 0\n",
    "#     den = ((beta**2)*p+r)\n",
    "#     if den !=0:\n",
    "#         fb = (1+beta**2)*p*r/((beta**2)*p+r)\n",
    "#     return fb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def log_cost_function(w: np.array, X: np.array, y: np.array) -> float:\n",
    "#     \"\"\"Calculates the log cost function for binary logistic regression\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     w : np.array\n",
    "#         Weights\n",
    "#     X : np.array\n",
    "#         Input values\n",
    "#     y : np.array\n",
    "#         Expected outputs\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     float\n",
    "#         Logistic cost function result\n",
    "#     \"\"\"\n",
    "#     y_pred = log_reg_predict(w, X)\n",
    "#     y_pred = utl.min_max_scaling(pd.Series(y_pred))[0]\n",
    "#     den = 1 + np.exp(y_pred)\n",
    "#     den[den == 0] = 1e-4\n",
    "#     h = 1/den\n",
    "#     return - (1/len(X))*np.sum(y*np.log(h) + (1-y)*np.log(1-h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lcf_for_min(w: np.array, *args: Tuple[np.array, np.array]) -> float:\n",
    "#     \"\"\"Calculates the log cost function for binary logistic regression in format necessary for minimization algorithm\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     w : np.array\n",
    "#         _description_\n",
    "\n",
    "#     **args: Tuple[np.array, np.array]\n",
    "#         np.array: Input values X\n",
    "#         np.array: Expected outputs y\n",
    "#     Returns\n",
    "#     -------\n",
    "#     float\n",
    "#         Logistic cost function result\n",
    "#     \"\"\"\n",
    "#     X = args[0]\n",
    "#     y = args[1]\n",
    "#     return log_cost_function(w, X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LogisticRegression:\n",
    "#     def __init__(self) -> None:\n",
    "#         self.w = None\n",
    "#         self.y_res = None\n",
    "\n",
    "#     def fit(self, X: pd.DataFrame, y: pd.Series, bias: float = 0, w: np.array = None):\n",
    "#         \"\"\"fit X data towards y target using multiclass logistic regression\n",
    "\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         X : pd.DataFrame\n",
    "#             Independent data\n",
    "#         y : pd.Series\n",
    "#             Target data\n",
    "#         bias : float, optional\n",
    "#             Constant vertical shift, by default 0\n",
    "#         w : np.array, optional\n",
    "#             Initial guess of the weights, by default all ones                     \n",
    "#         \"\"\"              \n",
    "#         if w is None:\n",
    "#             w = np.ones(X.shape[1]+1)\n",
    "\n",
    "#         y_res = pd.DataFrame()\n",
    "#         for cat in y.unique():\n",
    "#             y_np = y.copy().to_numpy()\n",
    "#             y_np[y_np!=cat]=-1\n",
    "#             y_np[y_np==cat]=1\n",
    "#             y_np[y_np==-1]=0\n",
    "#             y_res[cat] = y_np\n",
    "\n",
    "#         X_mod = LogisticRegression.add_bias_column(X)\n",
    "#         X_np = X_mod.to_numpy()\n",
    "\n",
    "#         # Inicializes data\n",
    "#         J = np.ones(len(y_res.columns))\n",
    "#         w_df = pd.DataFrame()\n",
    "#         for i,val in enumerate(y_res.columns):\n",
    "#             w_df[val] = 0.1*np.ones(X.shape[1]+1)\n",
    "#         w = w_df.to_numpy()\n",
    "#         y_c = y_res.to_numpy()\n",
    "\n",
    "#         # Minimizes the cost function\n",
    "#         for i,val in enumerate(y_res.columns):\n",
    "#             res = minimize(lcf_for_min, w[:,i], args=(X_np, y_c[:,i]))\n",
    "#             w[:,i] = res.x        \n",
    "#         self.w = w\n",
    "#         self.y_res = y_res\n",
    "\n",
    "#     def predict(self, X: np.array) -> np.array:\n",
    "#         \"\"\"Predicts resulting categories based on input data X\n",
    "\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         X : np.array\n",
    "#             Input data\n",
    "\n",
    "#         Returns\n",
    "#         -------\n",
    "#         np.array\n",
    "#             Predicted categories\n",
    "#         \"\"\"\n",
    "#         X_mod = LogisticRegression.add_bias_column(X)\n",
    "#         X_np = X_mod.to_numpy()\n",
    "\n",
    "#         # Predictions\n",
    "#         y_pred = pd.DataFrame()\n",
    "\n",
    "#         for i,val in enumerate(self.y_res.columns):\n",
    "#             y_pred[val] = self.log_reg_predict(X_np, i)\n",
    "#             y_pred[val] = utl.min_max_scaling(y_pred[val])[0]\n",
    "\n",
    "#         orig_cols = y_pred.columns\n",
    "#         y_pred['res'] = y_pred.apply(lambda x: np.argmax(x[orig_cols].to_numpy()) ,axis =1)\n",
    "#         return y_pred['res']\n",
    "\n",
    "#     def log_reg_predict(self, X: np.array, i: int) -> np.array:\n",
    "#         \"\"\"Single class prediction using a linear combination of input X and the weights w\n",
    "\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         X : np.array\n",
    "#             Input data with bias column of ones\n",
    "#         i : int\n",
    "#             Index of class of interests\n",
    "\n",
    "#         Returns\n",
    "#         -------\n",
    "#         np.array\n",
    "#             resulting predictions\n",
    "#         \"\"\"\n",
    "#         return (self.w[:,i]*X).sum(axis=1)\n",
    "\n",
    "#     @staticmethod\n",
    "#     def add_bias_column(X: pd.DataFrame) -> pd.DataFrame:\n",
    "#         \"\"\"Adds the column 'bias_col' of ones for the bias calculation\n",
    "\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         X : pd.DataFrame\n",
    "#             Input data\n",
    "\n",
    "#         Returns\n",
    "#         -------\n",
    "#         pd.DataFrame\n",
    "#             Input data plus bias column\n",
    "#         \"\"\"\n",
    "#         X_mod = X.copy()\n",
    "#         ones_aux = np.ones(X.shape[0])\n",
    "#         X_mod['bias_col'] = ones_aux\n",
    "#         cols = X_mod.columns\n",
    "#         cols_reordered = [cols[i-1] for i,x in enumerate(cols)]\n",
    "#         X_mod = X_mod[cols_reordered]\n",
    "#         return X_mod\n",
    "\n",
    "#     @staticmethod\n",
    "#     def log_cost_function(w: np.array, X: np.array, y: np.array) -> float:\n",
    "#         \"\"\"Calculates the log cost function for binary logistic regression\n",
    "\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         w : np.array\n",
    "#             Weights\n",
    "#         X : np.array\n",
    "#             Input values\n",
    "#         y : np.array\n",
    "#             Expected outputs\n",
    "\n",
    "#         Returns\n",
    "#         -------\n",
    "#         float\n",
    "#             Logistic cost function result\n",
    "#         \"\"\"\n",
    "#         y_pred = log_reg_predict(w, X)\n",
    "#         y_pred = utl.min_max_scaling(pd.Series(y_pred))[0]\n",
    "#         den = 1 + np.exp(y_pred)\n",
    "#         den[den == 0] = 1e-4\n",
    "#         h = 1/den\n",
    "#         return - (1/len(X))*np.sum(y*np.log(h) + (1-y)*np.log(1-h))\n",
    "\n",
    "#     @staticmethod\n",
    "#     def lcf_for_min(w: np.array, *args: Tuple[np.array, np.array]) -> float:\n",
    "#         \"\"\"Calculates the log cost function for binary logistic regression in format necessary for minimization algorithm\n",
    "\n",
    "#         Parameters\n",
    "#         ----------\n",
    "#         w : np.array\n",
    "#             _description_\n",
    "\n",
    "#         **args: Tuple[np.array, np.array]\n",
    "#             np.array: Input values X\n",
    "#             np.array: Expected outputs y\n",
    "#         Returns\n",
    "#         -------\n",
    "#         float\n",
    "#             Logistic cost function result\n",
    "#         \"\"\"\n",
    "#         X = args[0]\n",
    "#         y = args[1]\n",
    "#         return LogisticRegression.log_cost_function(w, X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/1.raw/customerClassification.csv')#, parse_dates=['DateTime'],index_col=['DateTime'])\n",
    "df.columns\n",
    "X_cols = ['Gender', 'Ever_Married', 'Age', 'Graduated', 'Profession',\n",
    "       'Work_Experience', 'Spending_Score', 'Family_Size',\n",
    "       'Segmentation']\n",
    "X_cat_cols = ['Gender', 'Ever_Married', 'Graduated', 'Profession',\n",
    "       'Spending_Score', 'Segmentation']\n",
    "y_col = 'Var_1'\n",
    "\n",
    "X = df[X_cols]\n",
    "X = X.fillna(0)\n",
    "\n",
    "for cat in X_cat_cols:\n",
    "    X[cat] = X[cat].astype('category').cat.codes\n",
    "\n",
    "for c in X.columns:\n",
    "    X[c] = utl.min_max_scaling(X[c])[0]\n",
    "\n",
    "\n",
    "y = df[y_col].fillna(0).astype('category').cat.codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  76,  133,  422,    0,  822, 1089,    0,   85, 5238,  203]),\n",
       " array([   0,    1,    1,    2,    3,    4,    4,    5,    6,    6,    7]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0         1         2         3         4         5         6  \\\n",
      "0     0.007455  0.023504  0.073360  0.139425  0.216374  0.012825  0.475590   \n",
      "1     0.008022  0.022724  0.063674  0.131283  0.153056  0.015512  0.559859   \n",
      "2     0.014263  0.014836  0.019408  0.069187  0.052840  0.005231  0.815867   \n",
      "3     0.006882  0.013833  0.025662  0.075907  0.055693  0.004169  0.811408   \n",
      "4     0.004236  0.023763  0.088309  0.102610  0.205378  0.024162  0.494449   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "8063  0.004405  0.017738  0.110331  0.097576  0.359212  0.014839  0.382423   \n",
      "8064  0.007121  0.014270  0.058246  0.098287  0.178705  0.009616  0.572363   \n",
      "8065  0.013147  0.025751  0.059368  0.122480  0.054810  0.010700  0.713290   \n",
      "8066  0.005643  0.024838  0.113858  0.134389  0.125577  0.023005  0.532876   \n",
      "8067  0.005945  0.020212  0.059403  0.123071  0.115180  0.008374  0.636436   \n",
      "\n",
      "             7  res  \n",
      "0     0.030103    6  \n",
      "1     0.033321    6  \n",
      "2     0.015589    6  \n",
      "3     0.009754    6  \n",
      "4     0.043007    6  \n",
      "...        ...  ...  \n",
      "8063  0.061262    6  \n",
      "8064  0.023671    6  \n",
      "8065  0.020943    6  \n",
      "8066  0.034411    6  \n",
      "8067  0.024381    6  \n",
      "\n",
      "[8068 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "lrm = LogisticRegression()\n",
    "lrm.fit(X, y)\n",
    "y_p = lrm.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       6\n",
       "1       6\n",
       "2       6\n",
       "3       6\n",
       "4       6\n",
       "       ..\n",
       "8063    6\n",
       "8064    6\n",
       "8065    6\n",
       "8066    6\n",
       "8067    6\n",
       "Name: res, Length: 8068, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\JupyterNotebooks\\2023\\ML Models\\MLModels\\notebooks\\../scripts\\utils.py:126: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return cm[i][i]/cm[:,i].sum()\n"
     ]
    }
   ],
   "source": [
    "cm = utl.confusion_matrix(y, y_p)\n",
    "acc = utl.accuracy_classification(cm)\n",
    "pres = utl.presicion_classification(cm)\n",
    "rec = utl.recall_classification(cm)\n",
    "f1 = utl.fbeta_classification(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    1,    0,   75,    0],\n",
       "       [   0,    0,    0,    0,    1,    0,  132,    0],\n",
       "       [   0,    0,    0,    0,   15,    0,  407,    0],\n",
       "       [   0,    0,    0,    0,   20,    0,  802,    0],\n",
       "       [   0,    0,    0,    0,   54,    0, 1035,    0],\n",
       "       [   0,    0,    0,    0,    5,    0,   80,    0],\n",
       "       [   0,    0,    0,    0,   41,    0, 5197,    0],\n",
       "       [   0,    0,    0,    0,    5,    0,  198,    0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(formatter={'float_kind':'{:4.0f}'.format})\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6508428358948934, 0.0, nan, nan)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, pres, rec, f1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\an2fe\\anaconda3\\envs\\mlmodels\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=0).fit(X,y)\n",
    "y_pred_skl_np = clf.predict(X)\n",
    "y_pred_skl = pd.Series(y_pred_skl_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\JupyterNotebooks\\2023\\ML Models\\MLModels\\notebooks\\../scripts\\utils.py:126: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return cm[i][i]/cm[:,i].sum()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6512146752602875, 0.0, nan, nan)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_skl = utl.confusion_matrix(y, y_pred_skl)\n",
    "acc_skl = utl.accuracy_classification(cm_skl)\n",
    "pres_skl = utl.presicion_classification(cm_skl)\n",
    "rec_skl = utl.recall_classification(cm_skl)\n",
    "f1_skl = utl.fbeta_classification(cm_skl)\n",
    "\n",
    "acc_skl, pres_skl, rec_skl, f1_skl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    2,    0,   74,    0],\n",
       "       [   0,    0,    0,    0,    1,    0,  132,    0],\n",
       "       [   0,    0,    0,    0,   16,    0,  406,    0],\n",
       "       [   0,    0,    0,    0,   20,    0,  802,    0],\n",
       "       [   0,    0,    0,    0,   55,    0, 1034,    0],\n",
       "       [   0,    0,    0,    0,    4,    0,   81,    0],\n",
       "       [   0,    0,    0,    0,   39,    0, 5199,    0],\n",
       "       [   0,    0,    0,    0,    5,    0,  198,    0]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_skl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlmodels",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
